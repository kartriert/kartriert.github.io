<!DOCTYPE html>
<html lang="de">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Travelogues</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/logo/Logo_weißerRand_transparent.PNG" rel="icon">
  <link href="assets/img/logo/Logo_weißerRand_transparent.PNG" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link
    href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i"
    rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: Kelly - v4.10.0
  * Template URL: https://bootstrapmade.com/kelly-free-bootstrap-cv-resume-html-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Header ======= -->
  <header id="header" class="fixed-top">
    <div class="container-fluid d-flex justify-content-between align-items-center">

      <h1 class="logo me-auto me-lg-0"><a href="index.html">Reiseberichte kar<span
            style="color: #0890a7">trier</span>t</a></h1>
      <!-- Uncomment below if you prefer to use an image logo -->
      <!-- <a href="index.html" class="logo"><img src="assets/img/logo.png" alt="" class="img-fluid"></a>-->

      <nav id="navbar" class="navbar order-last order-lg-0">
        <ul>
          <li><a href="karte.html">Karte</a></li>
          <li class="dropdown"><a class="active" href="ueber_projekt.html"><span>Über das Projekt</span></a>
            <ul>
              <li><a href="travelogues.html">NER & Travelogues</a></li>
              <li><a href="clustering.html">Clustering</a></li>
              <li><a href="karte_text.html">Karte</a></li>
              <li><a href="website.html">Website</a></li>
            </ul>
          </li>
          <li class="dropdown"><a href="DH_openscience.html"><span>DH & Open Science</span></a>
            <ul>
              <li><a href="dh-allgemein.html">DH</a></li>
              <li><a href="openscience.html">Open Science</a></li>
            </ul>
          </li>
          <li><a href="kontakt.html">Kontakt</a></li>
        </ul>
        <i class="bi bi-list mobile-nav-toggle"></i>
      </nav><!-- .navbar -->


    </div>

  </header><!-- End Header -->

  <main id="main">
    <section id="services" class="services">
      <div class="container" data-aos="fade-up">
        <div class="section-title">
          <h2>Travelogues</h2>
          <h3>Unsere Selbstfindungs<strong>reise</strong></h3>
        </div>
        <div>
          <p>Nach einer ersten Phase des Brainstormings bezüglich möglicher Themen eines Studi-Projektes und – nach
            erfolgreicher, wenn auch turbulenter – Auslese, folgte die Fokusschärfung. Es standen viele verschiedene
            Ideen und Methoden im Raum, die wir unter einen Hut bringen mussten. Dabei brillierte besonders eine Idee
            durch ihre Interdisziplinarität und das breite Spektrum möglicher Umsetzungen. Ein kartografiertes
            Multiversum fiktiver Charaktere und Orte, visualisiert auf einer Website und erschlossen durch Tools der
            Digital Humanities. Sherlock Holmes Spuren folgen oder die Scheibenwelt in 2D? Wir waren beinahe euphorisch,
            mögliche Umsetzungen zu testen!</p>
          <p>So wussten wir also ungefähr, wie unser Projektziel aussieht. Doch die Findungsphase unserer Studi-Gruppe
            war noch längst nicht abgeschlossen: Welche Werke eignen sich für ein Multiversum? Können wir Terry
            Pratchetts Werke verwenden und wenn ja, wo finden wir die Digitalisate? Wollen wir in dieser kurzen Zeit ein
            eigenes <span data-tooltip="Optical Character Recognition, sehr häufig als Akronym
            “OCR” anzutreffen, bezeichnet als Sammelbegriff Verfahren der digitalen, automatisierten Zeichenerkennung,
            bei denen Bilddateien in Textdateien umgewandelt werden. (Springmann, 2016, S. 1)">Optical Character
              Recognition (OCR)</span>-Projekt aufsetzen? Und vor allem: Verletzen wir damit womöglich Urheberrechte?
          </p>
        </div>
        <div>
          <h3>Wem das Korpus passt, der nutzt es nach</h3>
          <br>
          <p>Doch die Rettung nahte. Nachdem wir somit einige Zeit über den womöglich anstehenden Korpusaufbau
            gebrainstormt hatten, fiel unsere Wahl schließlich auf ein bereits bestehendes Korpus: Die <a href="https://www.travelogues-project.info/"><i>Travelogues</i></a> des
            gleichnamigen Projektes.
            <br>
            <p style="text-align: center;">
              <i class="bx bxs-quote-alt-left quote-icon-left" style="color: #0890a7;"></i>
              <strong style="font-style: italic;"> Das interdisziplinäre und internationale Projekt analysiert deutschsprachige Reiseberichte der
            Zeit 1500–1876 <br> aus dem Bestand der Österreichischen Nationalbibliothek. </strong> <i class="bx bxs-quote-alt-right quote-icon-right" style="color: #0890a7;"></i>
            <a href="https://www.travelogues-project.info/about_de/#:~:text=Das%20interdisziplin%C3%A4re%20und%20internationale%20Projekt%20analysiert%20deutschsprachige%20Reiseberichte%20der%20Zeit%201500%E2%80%931876%20aus%20dem%20Bestand%20der%20%C3%96sterreichischen%20Nationalbibliothek.">
              <br>(Travelogues/Über das Projekt)</a>
            </p>
          
          Endlich ein Korpus, das wie geschaffen für unser Projektvorhaben ist! Ging es zwar nicht mehr um die Idee
          eines fiktiven Multiversums, blieben doch im Kern die Ideen der Reiserouten und Visualisierung dynamisierter
          Ortserzählungen erhalten.
          </p><br>
          <p>Das Travelogues-Team generierte in der Laufzeit ihres Projektes ein Reisebericht-Korpus (mit 3.595
            Berichten datiert von 1500–1876) aus ursprünglich knapp 600.000 deutschsprachigen Büchern, die im Rahmen des
            Projektes <i>Austrian Books Online</i>der Österreichischen Nationalbibliothek digitalisiert wurden. Die
            Digitalisate wurden anschließend mit OCR in Volltexte umgewandelt und mit diversen computergestützten
            Methoden automatisch ausgewertet. Dazu gehört unter anderem auch eine automatisierte <span
              data-tooltip="Klassifikationsalgorithmen bilden einen Teil der Machine Learning Verfahren. Modelle dieser Art erlernen anhand von Trainingsdaten, Muster  der Gruppen in den Daten zu erkennen und neue Datenpunkte in solche bestehenden Gruppen einzusortieren.">Klassifikation</span>
            der Texte bezüglich ihrer "Reisebericht"-izität, um festzustellen, ob sie dem Korpus beigefügt werden sollen
            oder nicht.
          </p>
          <p>Das Korpus steht als Volltext-Sammlung auf <a href="https://github.com/travelogues">Github</a> zur
            Verfügung. Insgesamt 1.219 Reiseberichte können dort
            in Form von TXT-Dateien heruntergeladen werden. Des Weiteren wurden der Sammlung entsprechende Metadaten und
            Ergebnisse einer <span data-tooltip="Named Entitity Recognition, kurz NER, bezeichnet den
            computergestützten Prozess der Ermittlung von Eigennamen in digitalen Textdateien.">Named Entity
              Recognition (NER)</span> verfügbar gemacht.
          </p>
          <p>Wir entschieden uns für die Reiseberichte des 18. Jahrhunderts, da dies die umfangreichste verfügbare
            Volltextsammlung ist. Zudem schätzten wir die Qualität der Volltextdateien – nach stichprobenartiger
            Sichtung – besser ein, als die der vorigen Jahrhunderte.</p>
          <p>Einen Überblick des gesamten Korpusaufbaus gibt es <a href="ueber_projekt.html">hier</a> unter "Korpus".
          </p>
        </div>
        <div>
          <h3>Legacy featuring Forschungsdaten</h3>
          <br>
          <p>Natürlich war dieses Korpus nicht unser Schuh und wir nicht Aschenputtel: Es war kein perfekter Fit. Wie so
            oft bei der Nachnutzung bestehender Korpora oder anderer Forschungsdaten, mussten einige Vorkehrungen
            getroffen werden, um unsere geplanten Methoden einzusetzen. Da die Texte nicht manuell (oder automatisiert)
            postkorrigiert oder überprüft wurden, mussten wir zunächst eine grobe Fehleranalyse des Korpus durchführen.
            Des Weiteren überprüften wir die beigefügten Ergebnisse der NER auf systematische Fehler. Nach der Sichtung
            erarbeiteten wir einen Workflow, der von der Textkorrektur bis zum Erstellen der NER-Ergebnisse für die
            einzelnen Reiseberichte einige Stationen durchläuft. Außerdem wollten wir ein NER-Modell testen, das für
            historische Texte entwickelt wurde. Beim Querlesen der NER-Ergebnisse fiel uns außerdem auf, dass das
            automatische Mapping der erkannten Orts-Eigennamen mit der Geonames-Datenbasis nicht gut funktioniert hat.
            Dies liegt daran, dass die historischen Orte ambig sind. Zum Beispiel ist der erste Treffer für die Entität
            “Memphis” in Geonames der Ort in den USA. In dem betroffenen Reisebericht kann jedoch aus dem Kontext
            erschlossen werden, dass es sich hier um eine Erwähnung des Ortes “Memphis” in Ägypten handelt.
          </p>
          <p>Die Nachnutzbarkeit von Daten ist ein wiederkehrendes, heiß diskutiertes Thema in den Digital Humanities
            und findet in vielen Forschungsprojekten, auf Konferenzen oder Tagungen seinen Stammplatz in der Menge.
            Diese Tatsache fällt einem erst dann so richtig auf, wenn man selbst in einem Projekt arbeitet, in dem
            bestehende Forschungsdaten-Sammlungen nachgenutzt werden.</p>
        </div>
        <div>
          <h3>Post-Hoc Correction</h3>
          <br>
          <p>Im <a href="https://github.com/travelogues/travelogues-corpus">Travelogues-GitHub Repository</a>, sowie auf
            der Projektwebsite, wird bereits angekündigt, dass die
            OCRisierten Texte nicht manuell nachbearbeitet wurden. Das Travelogues-Team entwickelte indessen ein
            neuronales Netz für die automatische Postkorrektur, also ein eigens trainiertes <a
              href="https://doi.org/10.48550/ARXIV.2102.00583">Sprachmodell</a>. Es eignet sich
            vor allem für die Korrektur von OCR-Transkriptionsfehlern in historischen Texten. Das Trainingskorpus
            beinhaltet fast ausschließlich Texte aus dem 17. Jahrhundert., da hier bereits manuelle Transkriptionen der
            Texte vorlagen, die für das Training genutzt werden konnten.
          <p>Da wir uns jedoch für das umfangreichere Korpus des 18. Jahrhunderts entschieden hatten, eignete sich das
            Modell nur teilweise für die Nachkorrektur. Die Transkriptionsfehler in diesen Reiseberichten betreffen
            nämlich primär Sonderzeichen; unter anderem gehören dazu Zeilenumbrüche (Hyphenations), Schrägstriche im
            Fließtext oder Umlaute. Auch fehlende Zeichen in Wörtern kommen häufig vor.</p>
          <p> In einem Testlauf, bei dem wir die Texte aus dem 18. Jahrhundert mit Hilfe des Sprachmodells korrigierten,
            wurden richtig geschriebene Wörter "verschlimmbessert" (bspw. wurde aus "bulgaria" -> "bvlgaria" oder aus
            "vber-\nſchreiten" -> "vberſthſehſenſt"). Bedingt sind solche Fehler zumeist durch die starke Variation in
            der geschriebenen deutschen Sprache der Zeit. Da es sich grundsätzlich um Zeichenfehler handelt, die durch
            reguläre Ausdrücke verbessert werden können, haben wir uns dazu entschieden, ein eigenes, kurzes Skript
            dafür zu schreiben. Andere systematische Fehler, wie die Verwechslung von "u" und "v", sind jedoch kaum mit
            regulären Ausdrücken abzudecken.</p>
          <p> Die breite Fehlervarianz in der Schreibweise der Wörter ist bereits beim Sprachmodell von Lyu et. al.
            festgestellt worden, eine Korrektur ist jedoch schwierig, da eine strikte Normung ggf. zu kontextuellen
            Fehlern führen kann.</p>
          <p>Die Resultate unserer halb-automatischen Nachkorrektur sind, wie wir bereits erwarteten, gleichwertig
            fehlerbelastet. Da wir in dieser ersten Projektphase jedoch primär auf einer <span data-tooltip="Es ging um das Erkennen von Ortsnamen, die auch bei Texten mit relativ hoher Fehlerrate
            sehr gut erkannt werden konnten (bspw. anhand der Syntax im Wort-Kontext, mehr Infos folgen im
            nächsten Kapitel). Bei inhaltlichen Fragen, zum Beispiel einem Topic Modelling-Ansatz, wäre eine
            dezidierte Korrektur der Dateien womöglich empfehlenswert."><i>oberflächlichen</i> Ebene
              mit den
              Texten arbeiteten</span>, entschieden wir uns gegen eine umfangreiche,
            close-reading Nachkorrektur. Stattdessen speisten wir alle Reiseberichte in das NER-Modell und korrigierten
            anschließend die Ergebnisdateien.</p>
        </div>
        <div>
          <h3>Named Entity Recognition bei historischen Texten</h3>
          <br>
          <p>Bei der Named Entity Recognition (NER), einem Teilgebiet der Text-basierten Informationsextraktion, werden
            anhand bestimmter Merkmale Textstellen erschlossen, die Eigennamen enthalten. Eigennamen können
            beispielsweise Personen, Organisationen oder Ortsangaben betreffen. Zur Extraktion dienen überwachte
            Lernverfahren, die, basierend auf Beispielen dieser Merkmale, eine Klassifikation und Einordnung neuer
            Eigennamen-Vorkommen vornehmen können. Auch kontextuelle Informationen der Named Entitities, wie
            syntaktische Strukturen, können zur Erkennung genutzt werden. Diese haben wir – für jeden Reisebericht des
            18. Jahrhunderts in unserem Korpus – zusammen mit der Satznummer im Dokument und der Position der Worte
            innerhalb des Satzes extrahiert und als <span data-tooltip="JSON-Dateien werden verwendet, um einfache
            Datenstrukturen und Objekte im JSON-Format (JavaScript Object Notation) abzuspeichern. Sie bilden ein
            Standardformat für den Datenaustausch.">JSON Einträge</span> gespeichert. Entsprechend der Entstehungszeit der Reiseberichte,
            wählten wir ein Modell für NER in historischen Dokumenten. Jede Datei hat somit eine ihr entsprechende
            JSON-Datei mit den ermittelten Ortserwähnungen.</p>
          <p>Daraufhin erfolgte ein automatisierter Abgleich der erkannten Orte mit der GEO-Normdatenbank <a
              href="https://www.geonames.org/">GeoNames</a>;
            Identifier und Koordinaten des wahrscheinlichsten Suchtreffers wurden dem Datensatz hinzugefügt.</p>
          <p>Wie bereits oben erwähnt, war eine (zumindest stichprobenartige) Überprüfung und Postkorrektur der
            Ergebnisse für uns bedauernswert, aber unumgänglich. Ein zweischneidiges Schwert: Auf der einen Seite hatten
            wir weder genug Zeit (noch Personalressourcen), um ein umfassendes Textkorpus manuell zu korrigieren. Auf
            der anderen Seite stimmte uns die Aussicht auf eine so stark verfälschte Kartierung der Reiseberichte
            missmutig.</p>
          <p> Der gewählte Kompromiss umfasst zwei Komponenten. Zunächst brachen wir das "Korrekturkorpus" auf sechs
            Reiseberichte herunter, die unter uns Studis aufgeteilt und überprüft wurden. Auch hier wählten wir einen
            halbautomatischen Ansatz, bei dem falsche Einträge aus der GeoNames-Datenbank teils manuell, teils durch ein
            einfaches Python-Skript überarbeitet wurden. Der Fokus lag auf dem <span data-tooltip='Beispielsweise kontextualisierten wir den Reisebericht "Reisebeschreibung nach Arabien und anderen
            umliegenden Laendern" eindeutig in den arabischen Bereich und korrigierten insbesondere die Orte, die nicht
            in dieses Schema passen. Schwierigkeiten gab es in solchen Fällen vor allem mit Orten, die heutzutage nicht
            mehr den gleichen Namen haben, zu archäologischen Stätten geworden sind oder gleichnamige Vertreter in
            anderen Regionen haben. Auch die Erkennung von Personen mit Ortsbezeichnung in ihren Namen machten
            Schwierigkeiten.'>Ortskontext der Reiseberichte.</span> Die zweite Komponente umfasst ein Clusteringverfahren, das die computergestützte
            Bearbeitung großer Datenmengen zulässt, aber eine Unschärfe bei den einzelnen Datenpunkten eliminiert.
          </p>
        </div>
        <div>
          <ul>
            <li><a href="karte_text.html">Text über unsere Karte</a></li>
            <li><a href="clustering.html">Text über Clustering</a></li>
            <li><a href="Website.html">Text über die Website</a></li>
          </ul>
        </div>
      </div>
    </section>

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <footer id="footer">
    <div class="kontaktanfrage">
      Haben Sie Fragen, Anregungen oder Vorschläge? <br>
      Unter <a href="kontakt.html">Kontakt</a> können Sie uns jederzeit eine E-Mail schreiben.<br>
    </div>

    <br>

    <div class="referenzen">
      <div class="container">
        <a href="impressum.html">Impressum</a>
      </div>
      <div class="container">
        <a href="datenschutz.html">Datenschutzerklärung</a>
      </div>
    </div>

    <br>

    <div class="container">
      <div class="copyright">
        &copy; Copyright <strong><span>Kelly</span></strong>. All Rights Reserved
      </div>
      <div class="credits">
        <!-- All the links in the footer should remain intact. -->
        <!-- You can delete the links only if you purchased the pro version. -->
        <!-- Licensing information: https://bootstrapmade.com/license/ -->
        <!-- Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/kelly-free-bootstrap-cv-resume-html-template/ -->
        Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
      </div>
    </div>
  </footer><!-- End  Footer -->

  <div id="preloader"></div>
  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i
      class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/purecounter/purecounter_vanilla.js"></script>
  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/waypoints/noframework.waypoints.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>